{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_K-E_ehj-OI",
        "outputId": "564c815c-cdb5-4371-8d7b-873e7794f54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=fd52bcf04ab35c87caa5d506694575031262a55385d1f3f3dd0d6bd55b1a493c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "crK3MqE1k23w",
        "outputId": "aba812a0-6ed2-4675-820d-0d02d71f6246"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'animal_dataset.zip'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wget\n",
        "path ='https://www.kaggle.com/api/v1/datasets/download/snmahsa/animal-image-dataset-cats-dogs-and-foxes?dataset_version_number=1'\n",
        "wget.download(path, 'animal_dataset.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZqqDorsBsOYm"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# 檔案名稱\n",
        "file='animal_dataset.zip'\n",
        "ZIP = zipfile.ZipFile(file)\n",
        "ZIP.extractall()\n",
        "ZIP.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8v6XxDTsexR"
      },
      "source": [
        "# **1. 請輸出資料分布**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "BV07ev9aiCcN",
        "outputId": "9f45cfeb-8152-4bf4-b542-ed7cbaeaaa41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "每個資料夾的圖片數量: {'cat': 101, 'dog': 105, 'fox': 102}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# 設置默認字型為英文字型\n",
        "rcParams['font.sans-serif'] = ['Liberation Sans']\n",
        "rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "# 設定資料夾路徑\n",
        "base_dir = \"/content/Animal Image Dataset-Cats, Dogs, and Foxes\"  # 替換為你的資料夾路徑\n",
        "categories = [\"cat\", \"dog\", \"fox\"]  # 資料夾名稱\n",
        "\n",
        "# 初始化統計結果\n",
        "image_counts = {}\n",
        "\n",
        "# 統計每個資料夾中的圖片數量\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(base_dir, category)\n",
        "    if os.path.exists(folder_path):\n",
        "        # 計算圖片數量（只統計常見圖片格式）\n",
        "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        image_counts[category] = len(image_files)\n",
        "    else:\n",
        "        print(f\"資料夾不存在: {folder_path}\")\n",
        "        image_counts[category] = 0\n",
        "\n",
        "# 打印統計結果\n",
        "print(\"每個資料夾的圖片數量:\", image_counts)\n",
        "\n",
        "# 視覺化數據（直方圖）\n",
        "plt.bar(image_counts.keys(), image_counts.values(), color=['blue', 'green', 'orange'])\n",
        "plt.title(\"distribution\")\n",
        "plt.xlabel(\"categories\")\n",
        "plt.ylabel(\"picture amount\")\n",
        "plt.show()\n",
        "\n",
        "# 視覺化數據（圓餅圖）\n",
        "plt.pie(image_counts.values(), labels=image_counts.keys(), autopct='%1.1f%%', colors=['blue', 'green', 'orange'])\n",
        "plt.title(\"distribution\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKBV5LP6s_Yi"
      },
      "source": [
        "# **2. 請利用資料擴增將各類圖形增加資料**\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6KBjqzlsMNQ",
        "outputId": "1e19f615-772d-4566-a51c-d3c40634e97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料增強完成！增強後的資料已儲存於： /content/Augmented_Animal_Dataset\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# 原始資料路徑\n",
        "base_dir = \"/content/Animal Image Dataset-Cats, Dogs, and Foxes\"\n",
        "categories = [\"cat\", \"dog\", \"fox\"]  # 定義類別名稱\n",
        "\n",
        "# 增強後的資料儲存路徑\n",
        "augmented_base_dir = \"/content/Augmented_Animal_Dataset\"\n",
        "os.makedirs(augmented_base_dir, exist_ok=True)\n",
        "\n",
        "# 初始化 ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,       # 旋轉範圍\n",
        "    width_shift_range=0.2,   # 水平平移範圍\n",
        "    height_shift_range=0.2,  # 垂直平移範圍\n",
        "    shear_range=0.2,         # 剪切變換範圍\n",
        "    zoom_range=0.2,          # 縮放範圍\n",
        "    horizontal_flip=True,    # 水平翻轉\n",
        "    fill_mode='nearest'      # 填充模式\n",
        ")\n",
        "\n",
        "# 為每個類別進行資料增強\n",
        "for category in categories:\n",
        "    original_category_dir = os.path.join(base_dir, category)\n",
        "    augmented_category_dir = os.path.join(augmented_base_dir, category)\n",
        "    os.makedirs(augmented_category_dir, exist_ok=True)\n",
        "\n",
        "    # 處理每張圖片\n",
        "    for img_name in os.listdir(original_category_dir):\n",
        "        img_path = os.path.join(original_category_dir, img_name)\n",
        "        if img_path.endswith(('jpg', 'jpeg', 'png')):  # 確保是圖片格式\n",
        "            # 讀取圖片\n",
        "            img = tf.keras.utils.load_img(img_path)\n",
        "            img_array = tf.keras.utils.img_to_array(img)\n",
        "            img_array = img_array.reshape((1,) + img_array.shape)  # 調整形狀\n",
        "\n",
        "            # 使用 ImageDataGenerator 增強圖片\n",
        "            i = 0\n",
        "            for batch in datagen.flow(img_array, batch_size=1,\n",
        "                                      save_to_dir=augmented_category_dir,\n",
        "                                      save_prefix=\"aug\",\n",
        "                                      save_format=\"jpeg\"):\n",
        "                i += 1\n",
        "                if i >= 1:  # 每張圖片生成 5 張增強圖片\n",
        "                    break\n",
        "\n",
        "print(\"資料增強完成！增強後的資料已儲存於：\", augmented_base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v0FjCADwh4p"
      },
      "source": [
        "# **3. 請將資料分成訓練集和測試集**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBo05GLiwqN6",
        "outputId": "0c97bd7f-2516-40ad-b1c6-a3878eee3a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料分割完成！\n",
            "訓練集儲存在： /content/Train_Dataset\n",
            "測試集儲存在： /content/Test_Dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定義路徑\n",
        "original_base_dir = \"/content/Animal Image Dataset-Cats, Dogs, and Foxes\"\n",
        "augmented_base_dir = \"/content/Augmented_Animal_Dataset\"\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 建立訓練集與測試集資料夾\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 定義類別名稱\n",
        "categories = [\"cat\", \"dog\", \"fox\"]\n",
        "\n",
        "# 分割比例\n",
        "test_size = 0.25  # 測試集佔 20%\n",
        "\n",
        "# 處理每個類別\n",
        "for category in categories:\n",
        "    # 原始資料夾\n",
        "    original_category_dir = os.path.join(original_base_dir, category)\n",
        "    augmented_category_dir = os.path.join(augmented_base_dir, category)\n",
        "\n",
        "    # 合併原始資料與增強後的資料\n",
        "    all_images = []\n",
        "    if os.path.exists(original_category_dir):\n",
        "        all_images.extend([os.path.join(original_category_dir, img) for img in os.listdir(original_category_dir) if img.endswith(('jpg', 'jpeg', 'png'))])\n",
        "    if os.path.exists(augmented_category_dir):\n",
        "        all_images.extend([os.path.join(augmented_category_dir, img) for img in os.listdir(augmented_category_dir) if img.endswith(('jpg', 'jpeg', 'png'))])\n",
        "\n",
        "    # 分割訓練集與測試集\n",
        "    train_images, test_images = train_test_split(all_images, test_size=test_size, random_state=42)\n",
        "\n",
        "    # 建立類別資料夾\n",
        "    train_category_dir = os.path.join(train_dir, category)\n",
        "    test_category_dir = os.path.join(test_dir, category)\n",
        "    os.makedirs(train_category_dir, exist_ok=True)\n",
        "    os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "    # 複製圖片到訓練集\n",
        "    for img_path in train_images:\n",
        "        shutil.copy(img_path, train_category_dir)\n",
        "\n",
        "    # 複製圖片到測試集\n",
        "    for img_path in test_images:\n",
        "        shutil.copy(img_path, test_category_dir)\n",
        "\n",
        "print(\"資料分割完成！\")\n",
        "print(\"訓練集儲存在：\", train_dir)\n",
        "print(\"測試集儲存在：\", test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLdU3pzOMBWq"
      },
      "source": [
        "# 過程\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g4BZdGMGivB",
        "outputId": "626fe32e-f659-426f-bbb8-12283167dcc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 459 images belonging to 3 classes.\n",
            "Found 155 images belonging to 3 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4735104   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4828739 (18.42 MB)\n",
            "Trainable params: 4828739 (18.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 89s 6s/step - loss: 1.2384 - accuracy: 0.3747 - val_loss: 1.0963 - val_accuracy: 0.4452\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 86s 6s/step - loss: 1.0645 - accuracy: 0.4227 - val_loss: 1.0430 - val_accuracy: 0.3935\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 84s 6s/step - loss: 1.0386 - accuracy: 0.4924 - val_loss: 1.0262 - val_accuracy: 0.5290\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 86s 6s/step - loss: 0.9132 - accuracy: 0.5817 - val_loss: 0.9607 - val_accuracy: 0.5355\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 84s 6s/step - loss: 0.8106 - accuracy: 0.6427 - val_loss: 0.8494 - val_accuracy: 0.5871\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 85s 6s/step - loss: 0.7074 - accuracy: 0.6885 - val_loss: 0.8641 - val_accuracy: 0.6065\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 84s 6s/step - loss: 0.5635 - accuracy: 0.7669 - val_loss: 1.1490 - val_accuracy: 0.4968\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 83s 6s/step - loss: 0.4789 - accuracy: 0.8148 - val_loss: 0.8736 - val_accuracy: 0.6710\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 85s 6s/step - loss: 0.3775 - accuracy: 0.8540 - val_loss: 0.8609 - val_accuracy: 0.6968\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 85s 6s/step - loss: 0.2654 - accuracy: 0.9041 - val_loss: 0.8728 - val_accuracy: 0.6839\n",
            "5/5 [==============================] - 21s 4s/step - loss: 0.8728 - accuracy: 0.6839\n",
            "測試集準確率: 68.39%\n",
            "模型已儲存！\n",
            "正在使用圖片進行測試: /content/Test_Dataset/cat/aug_0_3299.jpeg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "預測結果: cat (信心度: 85.02%)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# 訓練集和測試集路徑\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 圖片大小設定\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. 資料預處理\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 2. 建立模型\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 分類數為 3：貓、狗、狐狸\n",
        "])\n",
        "\n",
        "# 顯示模型架構\n",
        "model.summary()\n",
        "\n",
        "# 3. 編譯模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 訓練模型\n",
        "EPOCHS = 8\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# 5. 評估模型\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"測試集準確率: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 6. 儲存模型\n",
        "model.save(\"/content/animal_classifier_model.h5\")\n",
        "print(\"模型已儲存！\")\n",
        "\n",
        "# 7. 測試模型預測\n",
        "def predict_image(image_path, model, train_generator):\n",
        "    try:\n",
        "        # 檢查測試圖片是否存在\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"圖片路徑不存在: {image_path}\")\n",
        "            return\n",
        "\n",
        "        # 加載並處理圖片\n",
        "        img = load_img(image_path, target_size=IMG_SIZE)\n",
        "        img_array = img_to_array(img) / 255.0  # 標準化\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 預測\n",
        "        predictions = model.predict(img_array)\n",
        "        class_indices = train_generator.class_indices\n",
        "        class_labels = {v: k for k, v in class_indices.items()}\n",
        "        predicted_class = class_labels[np.argmax(predictions)]\n",
        "        confidence = np.max(predictions)\n",
        "\n",
        "        # 顯示預測結果\n",
        "        print(f\"預測結果: {predicted_class} (信心度: {confidence * 100:.2f}%)\")\n",
        "        return predicted_class\n",
        "    except Exception as e:\n",
        "        print(f\"預測時發生錯誤: {e}\")\n",
        "\n",
        "# 測試用例\n",
        "test_image_dir = \"/content/Test_Dataset/cat\"\n",
        "test_images = os.listdir(test_image_dir)\n",
        "\n",
        "if test_images:\n",
        "    # 選擇第一張圖片進行測試\n",
        "    test_image_path = os.path.join(test_image_dir, test_images[0])\n",
        "    print(f\"正在使用圖片進行測試: {test_image_path}\")\n",
        "    predict_image(test_image_path, model, train_generator)\n",
        "else:\n",
        "    print(\"測試資料夾中沒有圖片！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1lsrZJVKeDh",
        "outputId": "cdf0213d-4491-4708-8432-622a02ac9bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 459 images belonging to 3 classes.\n",
            "Found 155 images belonging to 3 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 148, 148, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 74, 74, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               4735104   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4828739 (18.42 MB)\n",
            "Trainable params: 4828739 (18.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 94s 6s/step - loss: 1.2895 - accuracy: 0.3725 - val_loss: 1.0799 - val_accuracy: 0.3355\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 86s 6s/step - loss: 1.0773 - accuracy: 0.4074 - val_loss: 1.0359 - val_accuracy: 0.5032\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 86s 6s/step - loss: 1.0333 - accuracy: 0.4641 - val_loss: 1.0427 - val_accuracy: 0.4323\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 87s 6s/step - loss: 0.9273 - accuracy: 0.5861 - val_loss: 0.8833 - val_accuracy: 0.5935\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 90s 6s/step - loss: 0.8522 - accuracy: 0.6296 - val_loss: 0.8527 - val_accuracy: 0.5742\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 87s 6s/step - loss: 0.6761 - accuracy: 0.7233 - val_loss: 0.8241 - val_accuracy: 0.6516\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 89s 6s/step - loss: 0.5251 - accuracy: 0.7908 - val_loss: 0.8578 - val_accuracy: 0.6581\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 90s 6s/step - loss: 0.4279 - accuracy: 0.8148 - val_loss: 0.8575 - val_accuracy: 0.6645\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 89s 6s/step - loss: 0.3478 - accuracy: 0.8693 - val_loss: 0.9679 - val_accuracy: 0.6903\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 86s 6s/step - loss: 0.2241 - accuracy: 0.9216 - val_loss: 1.2225 - val_accuracy: 0.6387\n",
            "5/5 [==============================] - 20s 4s/step - loss: 1.2225 - accuracy: 0.6387\n",
            "測試集準確率: 63.87%\n",
            "模型已儲存！\n",
            "正在使用圖片進行測試: /content/Test_Dataset/cat/aug_0_3299.jpeg\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "預測結果: cat (信心度: 99.98%)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, LeakyReLU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# 訓練集和測試集路徑\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 圖片大小設定\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. 資料預處理\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 2. 建立模型，使用 LeakyReLU 激活函數\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), input_shape=(150, 150, 3)),\n",
        "    LeakyReLU(alpha=0.1),  # LeakyReLU 激活函數\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 分類數為 3：貓、狗、狐狸\n",
        "])\n",
        "\n",
        "# 顯示模型架構\n",
        "model.summary()\n",
        "\n",
        "# 3. 編譯模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 訓練模型\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# 5. 評估模型\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"測試集準確率: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 6. 儲存模型\n",
        "model.save(\"/content/animal_classifier_leakyrelu_model.h5\")\n",
        "print(\"模型已儲存！\")\n",
        "\n",
        "# 7. 測試模型預測\n",
        "def predict_image(image_path, model, train_generator):\n",
        "    try:\n",
        "        # 檢查測試圖片是否存在\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"圖片路徑不存在: {image_path}\")\n",
        "            return\n",
        "\n",
        "        # 加載並處理圖片\n",
        "        img = load_img(image_path, target_size=IMG_SIZE)\n",
        "        img_array = img_to_array(img) / 255.0  # 標準化\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 預測\n",
        "        predictions = model.predict(img_array)\n",
        "        class_indices = train_generator.class_indices\n",
        "        class_labels = {v: k for k, v in class_indices.items()}\n",
        "        predicted_class = class_labels[np.argmax(predictions)]\n",
        "        confidence = np.max(predictions)\n",
        "\n",
        "        # 顯示預測結果\n",
        "        print(f\"預測結果: {predicted_class} (信心度: {confidence * 100:.2f}%)\")\n",
        "        return predicted_class\n",
        "    except Exception as e:\n",
        "        print(f\"預測時發生錯誤: {e}\")\n",
        "\n",
        "# 測試用例\n",
        "test_image_dir = \"/content/Test_Dataset/cat\"\n",
        "test_images = os.listdir(test_image_dir)\n",
        "\n",
        "if test_images:\n",
        "    # 選擇第一張圖片進行測試\n",
        "    test_image_path = os.path.join(test_image_dir, test_images[0])\n",
        "    print(f\"正在使用圖片進行測試: {test_image_path}\")\n",
        "    predict_image(test_image_path, model, train_generator)\n",
        "else:\n",
        "    print(\"測試資料夾中沒有圖片！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYUOspS2OES0",
        "outputId": "a3169f7f-2b05-40a5-fb3f-5cbfa2808100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 459 images belonging to 3 classes.\n",
            "Found 155 images belonging to 3 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 63, 63, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 63, 63, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 30, 30, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 57600)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               7372928   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7393091 (28.20 MB)\n",
            "Trainable params: 7392899 (28.20 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "7/7 [==============================] - 55s 7s/step - loss: 11.1387 - accuracy: 0.3899\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 59s 8s/step - loss: 6.9736 - accuracy: 0.6027\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 53s 7s/step - loss: 2.7655 - accuracy: 0.6987\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 59s 8s/step - loss: 3.0198 - accuracy: 0.7054\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 53s 7s/step - loss: 1.4286 - accuracy: 0.8430\n",
            "3/3 [==============================] - 21s 6s/step - loss: 2.1780 - accuracy: 0.3419\n",
            "測試集準確率 (val_accuracy): 34.19%\n",
            "模型已儲存！\n",
            "正在使用圖片進行測試: /content/Test_Dataset/cat/aug_0_3299.jpeg\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "預測結果: cat (信心度: 91.23%)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# 訓練集和測試集路徑\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 圖片大小設定（降低解析度至 128x128）\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 1. 資料預處理\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 2. 建立輕量化模型\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 分類數為 3：貓、狗、狐狸\n",
        "])\n",
        "\n",
        "# 顯示模型架構\n",
        "model.summary()\n",
        "\n",
        "# 3. 編譯模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 訓練模型（快速訓練）\n",
        "EPOCHS = 5  # 減少 epoch 數量\n",
        "STEPS_PER_EPOCH = train_generator.samples // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# 5. 訓練完成後進行驗證評估\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"測試集準確率 (val_accuracy): {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 6. 儲存模型\n",
        "model.save(\"/content/animal_classifier_fast_model.h5\")\n",
        "print(\"模型已儲存！\")\n",
        "\n",
        "# 7. 測試模型預測\n",
        "def predict_image(image_path, model, train_generator):\n",
        "    try:\n",
        "        # 檢查測試圖片是否存在\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"圖片路徑不存在: {image_path}\")\n",
        "            return\n",
        "\n",
        "        # 加載並處理圖片\n",
        "        img = load_img(image_path, target_size=IMG_SIZE)\n",
        "        img_array = img_to_array(img) / 255.0  # 標準化\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 預測\n",
        "        predictions = model.predict(img_array)\n",
        "        class_indices = train_generator.class_indices\n",
        "        class_labels = {v: k for k, v in class_indices.items()}\n",
        "        predicted_class = class_labels[np.argmax(predictions)]\n",
        "        confidence = np.max(predictions)\n",
        "\n",
        "        # 顯示預測結果\n",
        "        print(f\"預測結果: {predicted_class} (信心度: {confidence * 100:.2f}%)\")\n",
        "        return predicted_class\n",
        "    except Exception as e:\n",
        "        print(f\"預測時發生錯誤: {e}\")\n",
        "\n",
        "# 測試用例\n",
        "test_image_dir = \"/content/Test_Dataset/cat\"\n",
        "test_images = os.listdir(test_image_dir)\n",
        "\n",
        "if test_images:\n",
        "    # 選擇第一張圖片進行測試\n",
        "    test_image_path = os.path.join(test_image_dir, test_images[0])\n",
        "    print(f\"正在使用圖片進行測試: {test_image_path}\")\n",
        "    predict_image(test_image_path, model, train_generator)\n",
        "else:\n",
        "    print(\"測試資料夾中沒有圖片！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KCh9_uk-whaC",
        "outputId": "c7fd3a60-c3ab-4b6e-8f23-4ce4c844c2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 491 images belonging to 3 classes.\n",
            "Found 155 images belonging to 3 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 74, 74, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4735104   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4828739 (18.42 MB)\n",
            "Trainable params: 4828739 (18.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 93s 6s/step - loss: 1.2168 - accuracy: 0.3727 - val_loss: 1.0648 - val_accuracy: 0.4129\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 91s 6s/step - loss: 1.0769 - accuracy: 0.4236 - val_loss: 1.0832 - val_accuracy: 0.3548\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 89s 6s/step - loss: 1.0497 - accuracy: 0.4705 - val_loss: 1.0304 - val_accuracy: 0.5032\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 86s 5s/step - loss: 1.0002 - accuracy: 0.5173 - val_loss: 0.9378 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 90s 6s/step - loss: 0.8953 - accuracy: 0.6090 - val_loss: 0.8475 - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.7569 - accuracy: 0.6925 - val_loss: 0.8421 - val_accuracy: 0.5613\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 87s 5s/step - loss: 0.6854 - accuracy: 0.7108 - val_loss: 0.7237 - val_accuracy: 0.6774\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 88s 6s/step - loss: 0.5447 - accuracy: 0.7780 - val_loss: 0.8329 - val_accuracy: 0.6516\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 92s 6s/step - loss: 0.4886 - accuracy: 0.8248 - val_loss: 0.7856 - val_accuracy: 0.7097\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 87s 5s/step - loss: 0.3924 - accuracy: 0.8513 - val_loss: 0.7817 - val_accuracy: 0.6903\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.7817 - accuracy: 0.6903\n",
            "測試集準確率: 69.03%\n",
            "模型已儲存！\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Test_Dataset/cat/aug_0_1964'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-19ca34ab6b31>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# 測試用例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mtest_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Test_Dataset/cat/aug_0_1964\"\u001b[0m  \u001b[0;31m# 替換為你的測試圖片路徑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-19ca34ab6b31>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Test_Dataset/cat/aug_0_1964'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# 訓練集和測試集路徑\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 圖片大小設定\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. 資料預處理\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 2. 建立模型\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 分類數為 3：貓、狗、狐狸\n",
        "])\n",
        "\n",
        "# 顯示模型架構\n",
        "model.summary()\n",
        "\n",
        "# 3. 編譯模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 訓練模型\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# 5. 評估模型\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"測試集準確率: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 6. 儲存模型\n",
        "model.save(\"/content/animal_classifier_model.h5\")\n",
        "print(\"模型已儲存！\")\n",
        "\n",
        "# 7. 測試模型預測\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = load_img(image_path, target_size=IMG_SIZE)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_indices = train_generator.class_indices\n",
        "    class_labels = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class = class_labels[np.argmax(predictions)]\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    print(f\"預測結果: {predicted_class} (信心度: {confidence * 100:.2f}%)\")\n",
        "    return predicted_class\n",
        "\n",
        "# 測試用例\n",
        "test_image_path = \"/content/Test_Dataset/cat/aug_0_1964\"  # 替換為你的測試圖片路徑\n",
        "predict_image(test_image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFkOYqgjwWhU"
      },
      "source": [
        "# **4. 請建立分類模型，將圖形進行辨識**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZAgilrP9Vm",
        "outputId": "6cc780ae-68d5-4ec1-bfad-89df30130355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 459 images belonging to 3 classes.\n",
            "Found 155 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               163968    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2422339 (9.24 MB)\n",
            "Trainable params: 164355 (642.01 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 84s 6s/step - loss: 0.7243 - accuracy: 0.7298 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 75s 5s/step - loss: 0.2352 - accuracy: 0.9259 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.1872 - accuracy: 0.9281 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 75s 5s/step - loss: 0.1692 - accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.1743 - accuracy: 0.9434 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.1268 - accuracy: 0.9542 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 75s 5s/step - loss: 0.0764 - accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.0739 - accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.1313 - accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 74s 5s/step - loss: 0.0780 - accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 134s 9s/step - loss: 0.8063 - accuracy: 0.7429 - val_loss: 0.0576 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 118s 8s/step - loss: 0.6180 - accuracy: 0.7887 - val_loss: 0.0594 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 114s 8s/step - loss: 0.4583 - accuracy: 0.8322 - val_loss: 0.0642 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 119s 8s/step - loss: 0.3642 - accuracy: 0.8649 - val_loss: 0.0656 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 119s 8s/step - loss: 0.2239 - accuracy: 0.9063 - val_loss: 0.0649 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0649 - accuracy: 0.9871\n",
            "測試集準確率: 98.71%\n",
            "模型已儲存！\n",
            "正在使用圖片進行測試: /content/Test_Dataset/cat/aug_0_3299.jpeg\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "預測結果: cat (信心度: 99.90%)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# 訓練集和測試集路徑\n",
        "train_dir = \"/content/Train_Dataset\"\n",
        "test_dir = \"/content/Test_Dataset\"\n",
        "\n",
        "# 圖片大小設定（MobileNetV2 標準大小為 224x224）\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. 資料預處理（包含資料增強）\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 2. 使用 MobileNetV2 預訓練模型\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # 凍結預訓練模型權重\n",
        "\n",
        "# 3. 建立模型\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 分類數為 3：貓、狗、狐狸\n",
        "])\n",
        "\n",
        "# 顯示模型架構\n",
        "model.summary()\n",
        "\n",
        "# 4. 編譯模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. 訓練模型（使用學習率調整）\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "# 解凍部分預訓練模型權重進行微調\n",
        "base_model.trainable = True\n",
        "fine_tune_at = len(base_model.layers) // 2  # 解凍後半部分層數\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 使用較低學習率進行微調\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 進行微調訓練\n",
        "FINE_TUNE_EPOCHS = 5\n",
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=FINE_TUNE_EPOCHS,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "# 6. 評估模型\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"測試集準確率: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 7. 儲存模型\n",
        "model.save(\"/content/animal_classifier_mobilenet_model.h5\")\n",
        "print(\"模型已儲存！\")\n",
        "\n",
        "# 8. 測試模型預測\n",
        "def predict_image(image_path, model, train_generator):\n",
        "    try:\n",
        "        # 檢查測試圖片是否存在\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"圖片路徑不存在: {image_path}\")\n",
        "            return\n",
        "\n",
        "        # 加載並處理圖片\n",
        "        img = load_img(image_path, target_size=IMG_SIZE)\n",
        "        img_array = img_to_array(img) / 255.0  # 標準化\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 預測\n",
        "        predictions = model.predict(img_array)\n",
        "        class_indices = train_generator.class_indices\n",
        "        class_labels = {v: k for k, v in class_indices.items()}\n",
        "        predicted_class = class_labels[np.argmax(predictions)]\n",
        "        confidence = np.max(predictions)\n",
        "\n",
        "        # 顯示預測結果\n",
        "        print(f\"預測結果: {predicted_class} (信心度: {confidence * 100:.2f}%)\")\n",
        "        return predicted_class\n",
        "    except Exception as e:\n",
        "        print(f\"預測時發生錯誤: {e}\")\n",
        "\n",
        "# 測試用例\n",
        "test_image_dir = \"/content/Test_Dataset/cat\"\n",
        "test_images = os.listdir(test_image_dir)\n",
        "\n",
        "if test_images:\n",
        "    # 選擇第一張圖片進行測試\n",
        "    test_image_path = os.path.join(test_image_dir, test_images[0])\n",
        "    print(f\"正在使用圖片進行測試: {test_image_path}\")\n",
        "    predict_image(test_image_path, model, train_generator)\n",
        "else:\n",
        "    print(\"測試資料夾中沒有圖片！\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d1d2a9ecc905ef171fa753a7e952cc3d53b061ba87f364110eb501a5ad998ef5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
